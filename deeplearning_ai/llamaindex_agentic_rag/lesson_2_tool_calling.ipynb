{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 2: Tool Calling\n",
    "https://learn.deeplearning.ai/courses/building-agentic-rag-with-llamaindex/lesson/3/tool-calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "OPENAI_MODEL = os.getenv(\"OPENAI_MODEL\")\n",
    "\n",
    "EMBEDDING_API_KEY = os.getenv(\"EMBEDDING_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make asyncio loops work inside Jupyter notebooks which already have loops under the hood\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.jinaai import JinaEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "Settings.embed_model = JinaEmbedding(api_key=EMBEDDING_API_KEY)\n",
    "Settings.llm = OpenAILike(model=OPENAI_MODEL, temperature=0.01, is_chat_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define a Simple Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "\n",
    "\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two integers together\"\"\"\n",
    "\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def mystery(x: int, y: int) -> int:\n",
    "    \"\"\"Mystery function that operates on top of two numbers\"\"\"\n",
    "\n",
    "    return (x + y) ** 2\n",
    "\n",
    "\n",
    "add_tool = FunctionTool.from_defaults(fn=add)\n",
    "\n",
    "mystery_tool = FunctionTool.from_defaults(fn=mystery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "llm = OpenAILike(model=OPENAI_MODEL, is_chat_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: mystery\n",
      "Action Input: {'x': 2, 'y': 9}\n",
      "\u001b[0m\u001b[1;3;34mObservation: 121\n",
      "\u001b[0m121\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    tools=[add_tool, mystery_tool],\n",
    "    user_msg=\"Tell me the output of the mystery function on 2 and 9\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define an Auto-Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(input_files=[\"./metagpt.pdf\"]).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=1024)\n",
    "nodes = splitter.get_nodes_from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprint\n",
      "METAGPT: M ETA PROGRAMMING FOR A\n",
      "MULTI -AGENT COLLABORATIVE FRAMEWORK\n",
      "Sirui Hong1∗, Mingchen Zhuge2∗, Jonathan Chen1, Xiawu Zheng3, Yuheng Cheng4,\n",
      "Ceyao Zhang4,Jinlin Wang1,Zili Wang ,Steven Ka Shing Yau5,Zijuan Lin4,\n",
      "Liyang Zhou6,Chenyu Ran1,Lingfeng Xiao1,7,Chenglin Wu1†,J¨urgen Schmidhuber2,8\n",
      "1DeepWisdom,2AI Initiative, King Abdullah University of Science and Technology,\n",
      "3Xiamen University,4The Chinese University of Hong Kong, Shenzhen,\n",
      "5Nanjing University,6University of Pennsylvania,\n",
      "7University of California, Berkeley,8The Swiss AI Lab IDSIA/USI/SUPSI\n",
      "ABSTRACT\n",
      "Remarkable progress has been made on automated problem solving through so-\n",
      "cieties of agents based on large language models (LLMs). Existing LLM-based\n",
      "multi-agent systems can already solve simple dialogue tasks. Solutions to more\n",
      "complex tasks, however, are complicated through logic inconsistencies due to\n",
      "cascading hallucinations caused by naively chaining LLMs. Here we introduce\n",
      "MetaGPT, an innovative meta-programming framework incorporating efficient\n",
      "human workflows into LLM-based multi-agent collaborations. MetaGPT en-\n",
      "codes Standardized Operating Procedures (SOPs) into prompt sequences for more\n",
      "streamlined workflows, thus allowing agents with human-like domain expertise\n",
      "to verify intermediate results and reduce errors. MetaGPT utilizes an assembly\n",
      "line paradigm to assign diverse roles to various agents, efficiently breaking down\n",
      "complex tasks into subtasks involving many agents working together. On col-\n",
      "laborative software engineering benchmarks, MetaGPT generates more coherent\n",
      "solutions than previous chat-based multi-agent systems. Our project can be found\n",
      "at https://github.com/geekan/MetaGPT.\n",
      "1 I NTRODUCTION\n",
      "Autonomous agents utilizing Large Language Models (LLMs) offer promising opportunities to en-\n",
      "hance and replicate human workflows. In real-world applications, however, existing systems (Park\n",
      "et al., 2023; Zhuge et al., 2023; Cai et al., 2023; Wang et al., 2023c; Li et al., 2023; Du et al., 2023;\n",
      "Liang et al., 2023; Hao et al., 2023) tend to oversimplify the complexities. They struggle to achieve\n",
      "effective, coherent, and accurate problem-solving processes, particularly when there is a need for\n",
      "meaningful collaborative interaction (Chen et al., 2024; Zhang et al., 2023; Dong et al., 2023; Zhou\n",
      "et al., 2023; Qian et al., 2023).\n",
      "Through extensive collaborative practice, humans have developed widely accepted Standardized\n",
      "Operating Procedures (SOPs) across various domains (Belbin, 2012; Manifesto, 2001; DeMarco &\n",
      "Lister, 2013). These SOPs play a critical role in supporting task decomposition and effective coor-\n",
      "dination. Furthermore, SOPs outline the responsibilities of each team member, while establishing\n",
      "standards for intermediate outputs. Well-defined SOPs improve the consistent and accurate exe-\n",
      "cution of tasks that align with defined roles and quality standards (Belbin, 2012; Manifesto, 2001;\n",
      "DeMarco & Lister, 2013; Wooldridge & Jennings, 1998). For instance, in a software company,\n",
      "Product Managers analyze competition and user needs to create Product Requirements Documents\n",
      "(PRDs) using a standardized structure, to guide the developmental process.\n",
      "Inspired by such ideas, we design a promising GPT -based Meta -Programming framework called\n",
      "MetaGPT that significantly benefits from SOPs. Unlike other works (Li et al., 2023; Qian et al.,\n",
      "2023), MetaGPT requires agents to generate structured outputs, such as high-quality requirements\n",
      "∗These authors contributed equally to this work.\n",
      "†Chenglin Wu (alexanderwu@fuzhi.ai) is the corresponding author, affiliated with DeepWisdom.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "vector_index = VectorStoreIndex(nodes)\n",
    "query_engine = vector_index.as_query_engine(similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import MetadataFilters\n",
    "\n",
    "query_engine = vector_index.as_query_engine(\n",
    "    similarity_top_k=2,\n",
    "    filters=MetadataFilters.from_dicts([{\"key\": \"page_label\", \"value\": \"2\"}]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MetaGPT has achieved state-of-the-art results in code generation benchmarks, with scores of 85.9% and 87.7% in Pass@1 on HumanEval and MBPP evaluations respectively. It has also demonstrated the ability to handle higher levels of software complexity and offer extensive functionality compared to other frameworks. Notably, in experimental evaluations, MetaGPT has achieved a 100% task completion rate, showcasing the robustness and efficiency of its design.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"What are some high-level results of MetaGPT?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page_label': '2', 'file_name': 'metagpt.pdf', 'file_path': 'metagpt.pdf', 'file_type': 'application/pdf', 'file_size': 16911937, 'creation_date': '2024-05-10', 'last_modified_date': '2024-05-10'}\n"
     ]
    }
   ],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the Auto-Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from llama_index.core.vector_stores import FilterCondition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_query(query: str, page_numbers: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Perform a vector search over an index.\n",
    "\n",
    "    query (str): the string query to be embedded.\n",
    "    page_numbers (List[str]): Filter by set of pages. Leave BLANK if we want to perform a vector search\n",
    "        over all pages. Otherwise, filter by the set of specified pages.\n",
    "    \"\"\"\n",
    "\n",
    "    metadata_dicts = [{\"key\": \"page_label\", \"value\": p} for p in page_numbers]\n",
    "\n",
    "    query_engine = vector_index.as_query_engine(\n",
    "        similarity_top_k=2,\n",
    "        filters=MetadataFilters.from_dicts(\n",
    "            metadata_dicts, condition=FilterCondition.OR\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query_tool = FunctionTool.from_defaults(name=\"vector_tool\", fn=vector_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The question is about the high-level results of MetaGPT described on page 2. I need to use a tool to retrieve this information.\n",
      "Action: vector_tool\n",
      "Action Input: {'query': 'high-level results of MetaGPT', 'page_numbers': ['2']}\n",
      "\u001b[0m\u001b[1;3;34mObservation: MetaGPT has achieved state-of-the-art results in code generation benchmarks, with 85.9% and 87.7% Pass@1 scores on HumanEval and MBPP evaluations, respectively. It has demonstrated the ability to handle higher levels of software complexity and offers extensive functionality. In experimental evaluations, MetaGPT has shown a 100% task completion rate, highlighting its robustness and efficiency in design.\n",
      "\u001b[0mMetaGPT has achieved state-of-the-art results in code generation benchmarks, with 85.9% and 87.7% Pass@1 scores on HumanEval and MBPP evaluations, respectively. It has demonstrated the ability to handle higher levels of software complexity and offers extensive functionality. In experimental evaluations, MetaGPT has shown a 100% task completion rate, highlighting its robustness and efficiency in design.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    tools=[vector_query_tool],\n",
    "    user_msg=\"What are the high-level results of MetaGPT as described on page 2?\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Let's add some other tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SummaryIndex\n",
    "from llama_index.core.tools import QueryEngineTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_index = SummaryIndex(nodes=nodes)\n",
    "summary_query_engine = summary_index.as_query_engine(\n",
    "    response_mode=\"tree_summarize\", use_async=True\n",
    ")\n",
    "\n",
    "summary_tool = QueryEngineTool.from_defaults(\n",
    "    name=\"summary_tool\",\n",
    "    query_engine=summary_query_engine,\n",
    "    description=\"Useful if you want to get a summary of MetaGPT\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: The user's question is about comparing MetaGPT and ChatDev, as described on page 8. I need to use a tool to retrieve this information from the document.\n",
      "Action: vector_tool\n",
      "Action Input: {'query': 'MetaGPT vs ChatDev', 'page_numbers': ['8']}\n",
      "\u001b[0m\u001b[1;3;34mObservation: MetaGPT demonstrates superior performance compared to ChatDev in various metrics, particularly on the challenging SoftwareDev dataset. MetaGPT achieves a higher score in executability, with a score of 3.75, which is very close to flawless. It also requires less time to complete tasks, taking only 503 seconds, which is significantly less than ChatDev's running time. In terms of code statistics and the cost of human revision, MetaGPT outperforms ChatDev. Although it uses more tokens overall, MetaGPT is more efficient, needing only 126.5 or 124.3 tokens to generate one line of code, compared to ChatDev's 248.9 tokens. These results emphasize the collaborative benefits of SOPs between multiple agents and showcase MetaGPT's capabilities in autonomous software generation.\n",
      "\u001b[0mMetaGPT demonstrates superior performance compared to ChatDev in various metrics, particularly on the challenging SoftwareDev dataset. MetaGPT achieves a higher score in executability, with a score of 3.75, which is very close to flawless. It also requires less time to complete tasks, taking only 503 seconds, which is significantly less than ChatDev's running time. In terms of code statistics and the cost of human revision, MetaGPT outperforms ChatDev. Although it uses more tokens overall, MetaGPT is more efficient, needing only 126.5 or 124.3 tokens to generate one line of code, compared to ChatDev's 248.9 tokens. These results emphasize the collaborative benefits of SOPs between multiple agents and showcase MetaGPT's capabilities in autonomous software generation.\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    tools=[vector_query_tool, summary_tool],\n",
    "    user_msg=\"What are the MetaGPT comparisons with ChatDev described on page 8?\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in response.source_nodes:\n",
    "    print(node.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mThought: (Implicit) I can answer without any more tools!\n",
      "Answer: summary_tool\n",
      "```python\n",
      "tool_call(input='The MetaGPT paper is a research paper that introduces a new method for training large language models. The method involves using a meta-learning approach to optimize the model\\'s hyperparameters and improve its performance on a variety of tasks. The paper presents results from experiments conducted on several benchmark datasets, and demonstrates that the proposed method outperforms other state-of-the-art techniques.')\n",
      "```\n",
      "\u001b[0msummary_tool\n",
      "```python\n",
      "tool_call(input='The MetaGPT paper is a research paper that introduces a new method for training large language models. The method involves using a meta-learning approach to optimize the model\\'s hyperparameters and improve its performance on a variety of tasks. The paper presents results from experiments conducted on several benchmark datasets, and demonstrates that the proposed method outperforms other state-of-the-art techniques.')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "response = llm.predict_and_call(\n",
    "    tools=[vector_query_tool, summary_tool],\n",
    "    user_msg=\"What is a summary of this MetaGPT paper?\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
