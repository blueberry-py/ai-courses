{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson 4: Persistence and Streaming\n",
    "\n",
    "https://learn.deeplearning.ai/courses/ai-agents-in-langgraph/lesson/5/persistence-and-streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv())\n",
    "\n",
    "MODEL = \"glm-4-air\"\n",
    "BASE_URL = \"https://open.bigmodel.cn/api/paas/v4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = TavilySearchResults(max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools: list, checkpointer, system: str = \"\") -> None:\n",
    "        self.system = system\n",
    "\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(node=\"llm\", action=self.call_openai)\n",
    "        graph.add_node(node=\"action\", action=self.take_action)\n",
    "        graph.add_conditional_edges(\n",
    "            source=\"llm\", path=self.exists_action, path_map={True: \"action\", False: END}\n",
    "        )\n",
    "        graph.add_edge(start_key=\"action\", end_key=\"llm\")\n",
    "        graph.set_entry_point(key=\"llm\")\n",
    "\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState) -> dict:\n",
    "        messages = state[\"messages\"]\n",
    "\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "\n",
    "        message = self.model.invoke(messages)\n",
    "\n",
    "        return {\"messages\": [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState) -> bool:\n",
    "        result = state[\"messages\"][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState) -> dict:\n",
    "        tool_calls = state[\"messages\"][-1].tool_calls\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "\n",
    "            result = self.tools[t[\"name\"]].invoke(t[\"args\"])\n",
    "            results.append(\n",
    "                ToolMessage(tool_call_id=t[\"id\"], name=t[\"name\"], content=str(result))\n",
    "            )\n",
    "\n",
    "        print(\"Back to the model!\")\n",
    "\n",
    "        return {\"messages\": results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=MODEL, base_url=BASE_URL)\n",
    "\n",
    "abot = Agent(model=model, tools=[tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather like in SF now?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8726260668035754131', 'function': {'arguments': '{\"query\": \"San Francisco weather\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 239, 'total_tokens': 255}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-bac0ad78-ebf9-41a3-a99a-187dcd708eed-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather'}, 'id': 'call_8726260668035754131'}], usage_metadata={'input_tokens': 239, 'output_tokens': 16, 'total_tokens': 255})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco weather'}, 'id': 'call_8726260668035754131'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717737044, \\'localtime\\': \\'2024-06-06 22:10\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717736400, \\'last_updated\\': \\'2024-06-06 22:00\\', \\'temp_c\\': 13.3, \\'temp_f\\': 55.9, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 10.5, \\'wind_kph\\': 16.9, \\'wind_degree\\': 310, \\'wind_dir\\': \\'NW\\', \\'pressure_mb\\': 1010.0, \\'pressure_in\\': 29.83, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 93, \\'cloud\\': 0, \\'feelslike_c\\': 12.1, \\'feelslike_f\\': 53.7, \\'windchill_c\\': 10.6, \\'windchill_f\\': 51.0, \\'heatindex_c\\': 12.1, \\'heatindex_f\\': 53.9, \\'dewpoint_c\\': 9.7, \\'dewpoint_f\\': 49.5, \\'vis_km\\': 13.0, \\'vis_miles\\': 8.0, \\'uv\\': 1.0, \\'gust_mph\\': 13.3, \\'gust_kph\\': 21.4}}\"}, {\\'url\\': \\'https://www.weathertab.com/en/c/e/07/united-states/california/san-francisco/\\', \\'content\\': \\'Temperature Forecast Normal. Avg High Temps 60 to 70 °F. Avg Low Temps 45 to 60 °F. Explore comprehensive July 2024 weather forecasts for San Francisco, including daily high and low temperatures, precipitation risks, and monthly temperature trends. Featuring detailed day-by-day forecasts, dynamic graphs of daily rain probabilities, and ...\\'}]', name='tavily_search_results_json', tool_call_id='call_8726260668035754131')]\n",
      "[AIMessage(content='The current weather in San Francisco is clear with a temperature of 13.3°C (55.9°F). The wind is blowing from the northwest at 10.5 mph (16.9 kph), and the humidity is 93%. It feels like 12.1°C (53.7°F) with the wind chill.', response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 777, 'total_tokens': 848}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-bbf53195-870f-46c8-84db-665f423d6192-0', usage_metadata={'input_tokens': 777, 'output_tokens': 71, 'total_tokens': 848})]\n"
     ]
    }
   ],
   "source": [
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8726255376635909922', 'function': {'arguments': '{\"query\": \"Los Angeles weather\"}', 'name': 'tavily_search_results_json'}, 'type': 'function', 'index': 0}]}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 883, 'total_tokens': 899}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ff3c8613-b480-42e8-8864-80a7842513e3-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather'}, 'id': 'call_8726255376635909922'}], usage_metadata={'input_tokens': 883, 'output_tokens': 16, 'total_tokens': 899})]\n",
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'Los Angeles weather'}, 'id': 'call_8726255376635909922'}\n",
      "Back to the model!\n",
      "[ToolMessage(content='[{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Los Angeles\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 34.05, \\'lon\\': -118.24, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1717737125, \\'localtime\\': \\'2024-06-06 22:12\\'}, \\'current\\': {\\'last_updated_epoch\\': 1717736400, \\'last_updated\\': \\'2024-06-06 22:00\\', \\'temp_c\\': 16.7, \\'temp_f\\': 62.1, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 5.6, \\'wind_kph\\': 9.0, \\'wind_degree\\': 300, \\'wind_dir\\': \\'WNW\\', \\'pressure_mb\\': 1012.0, \\'pressure_in\\': 29.87, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 90, \\'cloud\\': 100, \\'feelslike_c\\': 16.7, \\'feelslike_f\\': 62.1, \\'windchill_c\\': 19.9, \\'windchill_f\\': 67.9, \\'heatindex_c\\': 20.2, \\'heatindex_f\\': 68.3, \\'dewpoint_c\\': 14.4, \\'dewpoint_f\\': 57.8, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 1.0, \\'gust_mph\\': 6.8, \\'gust_kph\\': 10.9}}\"}, {\\'url\\': \\'https://www.accuweather.com/en/us/los-angeles/90012/july-weather/347625\\', \\'content\\': \\'Get the monthly weather forecast for Los Angeles, CA, including daily high/low, historical averages, to help you plan ahead.\\'}]', name='tavily_search_results_json', tool_call_id='call_8726255376635909922')]\n",
      "[AIMessage(content='The current weather in Los Angeles is overcast with a temperature of 16.7°C (62.1°F). The wind is blowing from the west-northwest at 5.6 mph (9.0 kph), and the humidity is 90%. It feels like 16.7°C (62.1°F) with no significant wind chill or heat index effect.', response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 1380, 'total_tokens': 1460}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-58817963-270e-49a5-ba3a-0445fd8f89c0-0', usage_metadata={'input_tokens': 1380, 'output_tokens': 80, 'total_tokens': 1460})]\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"What about in LA?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"Based on the current temperatures provided, Los Angeles is warmer with a temperature of 16.7°C (62.1°F), compared to San Francisco's temperature of 13.3°C (55.9°F).\", response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 1467, 'total_tokens': 1513}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-80594cce-92c9-4474-b94f-7ef1cb0cbc6f-0', usage_metadata={'input_tokens': 1467, 'output_tokens': 46, 'total_tokens': 1513})]\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AIMessage(content=\"The question is too vague to answer accurately without more context. I could assume it is asking about two specific places, objects, or times of day, but I need more information to proceed. I'll ask the user for clarification. \\n\\nWould you please specify what you are comparing in terms of temperature? Are you asking about two different locations, times of day, or something else?\", response_metadata={'token_usage': {'completion_tokens': 78, 'prompt_tokens': 213, 'total_tokens': 291}, 'model_name': 'glm-4-air', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5bab7ea8-f2ba-4b7e-af7a-e7070b3dc0c6-0', usage_metadata={'input_tokens': 213, 'output_tokens': 78, 'total_tokens': 291})]\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=\"Which one is warmer?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "\n",
    "abot = Agent(model=model, tools=[tool], checkpointer=memory, system=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"What is the weather like in SF now?\")]\n",
    "\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling: {'name': 'tavily_search_results_json', 'args': {'query': 'San Francisco current weather'}, 'id': 'call_8726261045992938055'}\n",
      "Back to the model!\n"
     ]
    }
   ],
   "source": [
    "async for event in abot.graph.astream_events(\n",
    "    {\"messages\": messages}, thread, version=\"v1\"\n",
    "):\n",
    "    kind = event[\"event\"]\n",
    "\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "\n",
    "        if content:\n",
    "            print(content, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
