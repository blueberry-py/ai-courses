{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 6: Question Answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.cohere import ChatCohere\n",
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./.chroma/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = CohereEmbeddings(model=\"embed-multilingual-light-v3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics of the lectures given?\"\n",
    "\n",
    "docs = vectordb.max_marginal_relevance_search(query=question, k=3)\n",
    "\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA Chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatCohere(model=\"command-light\", temperature=0.1),\n",
    "    retriever=vectordb.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I do not have access to any information regarding lectures or university courses. If you like, you can give me some information about the topic you would like to know about, and I will do my best to provide you with a relevant response.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \\\n",
    "    If you don't know the answer, just say that you don't know, \\\n",
    "    don't try to make up an answer. Use three sentences maximum. \\\n",
    "    Keep the answer as concise as possible. Always say \"thanks for asking!\" \\\n",
    "    at the end of the answer. \\\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\\n\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], template='Use the following pieces of context to answer the question at the end.     If you don\\'t know the answer, just say that you don\\'t know,     don\\'t try to make up an answer. Use three sentences maximum.     Keep the answer as concise as possible. Always say \"thanks for asking!\"     at the end of the answer. {context}\\nQuestion: {question}\\nHelpful Answer:\\n\\n')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QA_CHAIN_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatCohere(model=\"command-light\", temperature=0.1),\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a topic from the lectures given?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the provided information, it seems the lecture is about teaching probability and how it is intertwined with the Likelihood and parameters. Probability is a branch of mathematics that studies the likelihood or chance of a given event to occur. Using the provided information, the probability is a topic that is discussed and taught in the lecture. Hence, the answer is yes. \n",
      "Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta as the probability of Y given X paramete rized by theta. And so this is going to be \n",
      "the product over my training set like that. Which is, in turn, going to be a product of those \n",
      "Gaussian densities that I wrot e down just now, right? Okay?  \n",
      "Then in parts of notation, I guess, I define th is term here to be the likelihood of theta. \n",
      "And the likely of theta is just the probability of the data Y, right? Given X and prioritized \n",
      "by theta. To test the likeli hood and probability are often confused. So the likelihood of \n",
      "theta is the same thing as the probability of  the data you saw. So likely and probably are, \n",
      "sort of, the same thing. Except that when  I use the term likelihood I’m trying to \n",
      "emphasize that I’m taking this thing and view ing it as a function of  theta. Okay? So \n",
      "likelihood and for probability, th ey’re really the same thing except that when I want to \n",
      "view this thing as a function of theta holding X and Y fix are then called likelihood. \n",
      "Okay? So hopefully you hear me say the like lihood of the parameters and the probability\n"
     ]
    }
   ],
   "source": [
    "print(result[\"source_documents\"][0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA chain types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_mr = RetrievalQA.from_chain_type(\n",
    "    llm=ChatCohere(model=\"command-light\", temperature=0.1),\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"map_reduce\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain_mr.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot give you a definitive answer to that question as it depends on the specific university course and syllabus. I can tell you that probability is a mathematical concept that relates to the likelihood of an event happening, or the measurement of how likely it is that a certain outcome will occur. \n",
      "\n",
      "Probability is a broad topic and is discussed in many university courses, typically within statistics and mathematics programs. It is widely used in many of the physical sciences, such as in the field of quantum mechanics where it is used to predict the likelihood of an electron occupying a specific energy state. It is also used in the biological sciences and sociology when recording and analyzing data. \n",
      "\n",
      "If you provide more information about the course you are interested in, I can give you a better idea of the topics discussed.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain_rf = RetrievalQA.from_chain_type(\n",
    "    llm=ChatCohere(model=\"command-light\", temperature=0.1),\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    chain_type=\"refine\",\n",
    ")\n",
    "\n",
    "result = qa_chain_rf.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you for providing this additional context from the lecture. Let's use this to refine our understanding. \n",
      "\n",
      "According to the lecture excerpt, Professor Andrew Ng makes two important points:\n",
      "1. The choice of the sigmoid function in logistic regression - Professor Ng states that the sigmoid function, also known as the logistic function, is chosen primarily for two reasons: first, it belongs to the broader class of generalized linear models, which provides a useful conceptual framework; second, there are certain aesthetic considerations that make the choice particularly appealing in this context.\n",
      "2. Probabilistic interpretation - Professor Ng assigns a probabilistic interpretation to the output of the sigmoid function, implying that the function estimates the probability of the binary outcome $Y$ taking the value of one.\n",
      "\n",
      "Taking these points into account, the topic of probability is explicitly addressed in the lecture, particularly in the context of machine learning and statistical modelling. Understanding the choice of the sigmoid function and its probabilistic interpretation is crucial for comprehending the rationale behind logistic regression in predictive modelling. Therefore, the updated answer to the question is: \"Yes, the topic of probability is strongly related to the lectures given, especially in the context of statistical modelling and machine learning courses, as it is directly addressed and tied to the choice of the sigmoid function and its probabilistic interpretation in logistic regression.\" \n",
      "\n",
      "I hope this refinement helps provide greater clarity on the relation between the lecture content and the topic of probability.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA limitations\n",
    "\n",
    "QA fails to preserve conversational history.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=ChatCohere(model=\"command-light\", temperature=0.1),\n",
    "    retriever=vectordb.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a topic of the lectures given?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most definitely! Probability is a fundamental concept that underlies many areas of computer science and data science, including statistics, machine learning, and data analysis. It is a topic that is frequently covered in lectures related to these fields. \n",
      "\n",
      "Probability enables us to quantify uncertainty, make informed decisions, and understand the likelihood of various events occurring. It plays a crucial role in understanding data, making predictions, and forming the basis for many machine learning algorithms. \n",
      "\n",
      "In lectures focused on statistics and data analysis, probability is typically introduced as a way to model uncertainty by assigning probabilities to events based on observed data. This allows for the analysis of patterns and the drawing of inferences from the data. \n",
      "\n",
      "In the context of machine learning, probability concepts are employed in algorithms that learn from data to make predictions or classify new, unseen instances. Techniques like Bayesian inference, probability theory, and probability distributions are key components of machine learning systems. \n",
      "\n",
      "Overall, the study of probability is essential for graduates and professionals in computer science and data science roles, as it empowers them to work with data, make predictions, and build robust systems that can handle uncertainty.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The specific prerequisites needed for a particular task or goal will depend on the nature of that task or goal. Generally, prerequisites are necessary to ensure that individuals have the knowledge, skills, and abilities needed to succeed in a particular role or endeavor. \n",
      "\n",
      "Educational prerequisites, for example, are often necessary for career paths where in-depth knowledge and understanding of a particular subject is required. Taking a physics degree, for instance, would require an understanding of advanced mathematical concepts and previous proficiency in physics and chemistry. \n",
      "\n",
      "Similarly, prerequisites may be needed in other aspects of life, such as learning a new skill or pursuing a hobby. For instance, learning how to play the piano would require prerequisite skills in reading music and having some knowledge of music theory. \n",
      "\n",
      "In some cases, prerequisites may not be necessary for a particular task or goal, especially if the objective is more straightforward or introductory in nature. It's important to consider each situation individually and to consult with appropriate guidance, such as educators, supervisors, or mentors, to determine what prerequisites, if any, are needed.\n"
     ]
    }
   ],
   "source": [
    "question = \"why are those prerequesites needed?\"\n",
    "\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, The LLM response varies. Some responses do include a reference to probability which might be gleaned from referenced documents. The point is simply that the model does not have access to past questions or answers, this will be covered in the next lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
