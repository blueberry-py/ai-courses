{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 7: Chat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain, RetrievalQA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models.cohere import ChatCohere\n",
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./.chroma/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = CohereEmbeddings(model=\"embed-multilingual-light-v3.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "\n",
    "docs = vectordb.similarity_search(question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle of class, but because there won't be video you can safely sit there and make faces \n",
      "at me, and that won't show, okay?  \n",
      "Let's see. I also handed out this â€” ther e were two handouts I hope most of you have, \n",
      "course information handout. So let me just sa y a few words about parts of these. On the \n",
      "third page, there's a section that says Online Resources.  \n",
      "Oh, okay. Louder? Actually, could you turn up the volume? Testing. Is this better? \n",
      "Testing, testing. Okay, cool. Thanks.\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello to you as well! I'm your AI-assistant chatbot, ready to help you with any task or to have a meaningful conversation. Feel free to ask me whatever you'd like, and we can get started!\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatCohere(model=\"command-light\", temperature=0)\n",
    "\n",
    "llm.invoke(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Use the following pieces of context to answer the question \\\n",
    "    at the end. If you don't know the answer, just say that you don't know, \\\n",
    "    don't try to make up an answer. Use three sentences maximum. \\\n",
    "    Keep the answer as concise as possible. Always say \"thanks for asking!\" \\\n",
    "    at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\\n\n",
    "\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a topic from the lecture material that you can retrieve?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot retrieve the specific topic of probability in this context, as the provided context does not mention it. Having a good understanding of probability and statistics is essential in machine learning. It is used to understand the likelihood of different events occurring and is a fundamental concept in the field of data analysis. It is one of the topics that will be covered in a refresher session for those who need it in the discussion sections for the course on machine learning. \n",
      "If you need more information on probability or any other topic related to machine learning, feel free to ask! \n",
      "Thanks for asking!\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain.invoke({\"query\": question})\n",
    "\n",
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ConversationalRetrievalChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Is probability a topic of the lecture material that you can retrieve?\"\n",
    "\n",
    "result = qa.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Probability is most certainly a topic that can be discussed and retrieved by the databases I have access to. \n",
      "\n",
      "Probability makes it possible to predict the likelihood of occurrence of a spontaneous event or the repetition of an event that has a degree of uncertainty. The study of probability is the backbone of statistical analysis and is employed by data scientists and analysts, among other professionals. Would you like further clarification on the definition and applications of probability, or any specific information on what materials I can provide for you?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the name of the topic I just asked?\"\n",
    "\n",
    "result = qa.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic of Probability is likely being discussed with regards to a mathematical context. Could you provide some additional information about the previous topic of discussion? This will help me to provide more relevant information.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a chatbot that works on your documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores.docarray import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_db(file, chain_type, k):\n",
    "    loader = PyPDFLoader(file_path=file)\n",
    "    documents = loader.load()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "\n",
    "    embeddings = CohereEmbeddings()\n",
    "    db = DocArrayInMemorySearch.from_documents(documents=docs, embedding=embeddings)\n",
    "\n",
    "    retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": k})\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=ChatCohere(model=\"command-light\", temperature=0),\n",
    "        chain_type=chain_type,\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "        return_generated_question=True,\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "import param\n",
    "\n",
    "\n",
    "class cbfs(param.Parameterized):\n",
    "    chat_history = param.List([])\n",
    "    answer = param.String(\"\")\n",
    "    db_query = param.String(\"\")\n",
    "    db_response = param.List([])\n",
    "\n",
    "    def __init__(self, **params):\n",
    "        super(cbfs, self).__init__(**params)\n",
    "        self.panels = []\n",
    "        self.loaded_file = \"docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    "        self.qa = load_db(self.loaded_file, \"stuff\", 4)\n",
    "\n",
    "    def call_load_db(self, count):\n",
    "        if count == 0 or file_input.value is None:  # init or no file specified :\n",
    "            return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "        else:\n",
    "            file_input.save(\"temp.pdf\")  # local copy\n",
    "            self.loaded_file = file_input.filename\n",
    "            button_load.button_style = \"outline\"\n",
    "            self.qa = load_db(\"temp.pdf\", \"stuff\", 4)\n",
    "            button_load.button_style = \"solid\"\n",
    "        self.clr_history()\n",
    "        return pn.pane.Markdown(f\"Loaded File: {self.loaded_file}\")\n",
    "\n",
    "    def convchain(self, query):\n",
    "        if not query:\n",
    "            return pn.WidgetBox(\n",
    "                pn.Row(\"User:\", pn.pane.Markdown(\"\", width=600)), scroll=True\n",
    "            )\n",
    "        result = self.qa({\"question\": query, \"chat_history\": self.chat_history})\n",
    "        self.chat_history.extend([(query, result[\"answer\"])])\n",
    "        self.db_query = result[\"generated_question\"]\n",
    "        self.db_response = result[\"source_documents\"]\n",
    "        self.answer = result[\"answer\"]\n",
    "        self.panels.extend(\n",
    "            [\n",
    "                pn.Row(\"User:\", pn.pane.Markdown(query, width=600)),\n",
    "                pn.Row(\n",
    "                    \"ChatBot:\",\n",
    "                    pn.pane.Markdown(\n",
    "                        self.answer, width=600, style={\"background-color\": \"#F6F6F6\"}\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "        inp.value = \"\"  # clears loading indicator when cleared\n",
    "        return pn.WidgetBox(*self.panels, scroll=True)\n",
    "\n",
    "    @param.depends(\n",
    "        \"db_query \",\n",
    "    )\n",
    "    def get_lquest(self):\n",
    "        if not self.db_query:\n",
    "            return pn.Column(\n",
    "                pn.Row(\n",
    "                    pn.pane.Markdown(\n",
    "                        \"Last question to DB:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "                    )\n",
    "                ),\n",
    "                pn.Row(pn.pane.Str(\"no DB accesses so far\")),\n",
    "            )\n",
    "        return pn.Column(\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(\"DB query:\", styles={\"background-color\": \"#F6F6F6\"})\n",
    "            ),\n",
    "            pn.pane.Str(self.db_query),\n",
    "        )\n",
    "\n",
    "    @param.depends(\n",
    "        \"db_response\",\n",
    "    )\n",
    "    def get_sources(self):\n",
    "        if not self.db_response:\n",
    "            return\n",
    "        rlist = [\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(\n",
    "                    \"Result of DB lookup:\", styles={\"background-color\": \"#F6F6F6\"}\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        for doc in self.db_response:\n",
    "            rlist.append(pn.Row(pn.pane.Str(doc)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    @param.depends(\"convchain\", \"clr_history\")\n",
    "    def get_chats(self):\n",
    "        if not self.chat_history:\n",
    "            return pn.WidgetBox(\n",
    "                pn.Row(pn.pane.Str(\"No History Yet\")), width=600, scroll=True\n",
    "            )\n",
    "        rlist = [\n",
    "            pn.Row(\n",
    "                pn.pane.Markdown(\n",
    "                    \"Current Chat History variable\",\n",
    "                    styles={\"background-color\": \"#F6F6F6\"},\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        for exchange in self.chat_history:\n",
    "            rlist.append(pn.Row(pn.pane.Str(exchange)))\n",
    "        return pn.WidgetBox(*rlist, width=600, scroll=True)\n",
    "\n",
    "    def clr_history(self, count=0):\n",
    "        self.chat_history = []\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = cbfs()\n",
    "\n",
    "file_input = pn.widgets.FileInput(accept=\".pdf\")\n",
    "button_load = pn.widgets.Button(name=\"Load DB\", button_type=\"primary\")\n",
    "button_clearhistory = pn.widgets.Button(name=\"Clear History\", button_type=\"warning\")\n",
    "button_clearhistory.on_click(cb.clr_history)\n",
    "inp = pn.widgets.TextInput(placeholder=\"Enter text hereâ€¦\")\n",
    "\n",
    "bound_button_load = pn.bind(cb.call_load_db, button_load.param.clicks)\n",
    "conversation = pn.bind(cb.convchain, inp)\n",
    "\n",
    "jpg_pane = pn.pane.Image(\"./img/convchain.jpg\")\n",
    "\n",
    "tab1 = pn.Column(\n",
    "    pn.Row(inp),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(conversation, loading_indicator=True, height=300),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab2 = pn.Column(\n",
    "    pn.panel(cb.get_lquest),\n",
    "    pn.layout.Divider(),\n",
    "    pn.panel(cb.get_sources),\n",
    ")\n",
    "tab3 = pn.Column(\n",
    "    pn.panel(cb.get_chats),\n",
    "    pn.layout.Divider(),\n",
    ")\n",
    "tab4 = pn.Column(\n",
    "    pn.Row(file_input, button_load, bound_button_load),\n",
    "    pn.Row(\n",
    "        button_clearhistory,\n",
    "        pn.pane.Markdown(\"Clears chat history. Can use to start a new topic\"),\n",
    "    ),\n",
    "    pn.layout.Divider(),\n",
    "    pn.Row(jpg_pane.clone(width=400)),\n",
    ")\n",
    "dashboard = pn.Column(\n",
    "    pn.Row(pn.pane.Markdown(\"# ChatWithYourData_Bot\")),\n",
    "    pn.Tabs(\n",
    "        (\"Conversation\", tab1),\n",
    "        (\"Database\", tab2),\n",
    "        (\"Chat History\", tab3),\n",
    "        (\"Configure\", tab4),\n",
    "    ),\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
