{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson 5: Retrieval\n",
    "\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorstore retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.cohere import CohereEmbeddings\n",
    "from langchain_community.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = \"./.chroma/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = CohereEmbeddings(model=\"embed-multilingual-light-v3.0\")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in-memory\n",
    "smalldb = Chroma.from_texts(texts=texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(query=question, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(query=question, k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "In last lesson we introduced one problem: how to enforce diversity in the search results.\n",
    "\n",
    "**Maximum marginal relevance** strives to achieve both relevance to the query and diversity among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What did they say about matlab?\"\n",
    "\n",
    "doc_ss = vectordb.similarity_search(query=question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people \n"
     ]
    }
   ],
   "source": [
    "print(doc_ss[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people \n"
     ]
    }
   ],
   "source": [
    "print(doc_ss[1].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with MMR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(query=question, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "those homeworks will be done in either MATLA B or in Octave, which is sort of — I \n",
      "know some people \n"
     ]
    }
   ],
   "source": [
    "print(docs_mmr[0].page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "into his office and he said, \"Oh, professo r, professor, thank you so much for your \n",
      "machine learnin\n"
     ]
    }
   ],
   "source": [
    "print(docs_mmr[1].page_content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Addressing Specificity: working with metadata\n",
    "\n",
    "In last lesson, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on **metadata**.\n",
    "\n",
    "**metadata** provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    filter={\"source\": \"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    "\n",
    "1. The query string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.query_constructor.schema import AttributeInfo\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_community.llms.cohere import Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, \\\n",
    "            should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, \\\n",
    "            `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, \\\n",
    "            or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_content_description = \"Lecture notes\"\n",
    "\n",
    "llm = Cohere(model=\"command-light\", temperature=0.1)\n",
    "\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm=llm,\n",
    "    vectorstore=vectordb,\n",
    "    document_contents=document_content_description,\n",
    "    metadata_field_info=metadata_field_info,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the third lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 2, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n",
      "{'page': 0, 'source': 'docs/cs229_lectures/MachineLearning-Lecture03.pdf'}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional tricks: compression\n",
    "\n",
    "Another approach for improving the quality of retrieved docs is compression.\n",
    "\n",
    "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
    "\n",
    "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
    "\n",
    "Contextual compression is meant to fix this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs: list) -> None:\n",
    "    print(\n",
    "        f\"\\n{'-' * 100}\\n\".join(\n",
    "            [f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Cohere(model=\"command-light\", temperature=0.1)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "compressed_docs = compressor_retriever.get_relevant_documents(query=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='I extracted the following:\\n\\n\"So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \\\\\"Oh, professor, thank you so much for your...\"\\n\\nThis is the part of the context that might be relevant to answering the question.', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='I extracted the following:\\n\\n\"So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \\\\\"Oh, professor, thank you so much for your...\"\\n\\nThis is the part of the context that might be relevant to answering the question.', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content='The relevant parts from the context are:\\n\\n- They talked about machine learning and how it helped with his work, and how he uses it daily. \\n\\n- They also mentioned a picture of his big house, which could be related to his success with the skills learned and possibly income. \\n\\nThese are the parts that are most relevant to answering the question.', metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'}),\n",
       " Document(page_content=\"The extracted relevant parts include:\\n\\n- They are discussing MATLAB and how it helps with machine learning and making money.\\n- The conversation revolves around learning and using MATLAB as a tool to improve the student's knowledge and further career.\\n\\n- The conversation highlights the importance of MATLAB in machine learning and how it can help students create valuable skills and build their careers. \\n\\nThese are the relevant parts of the context provided to answer the question.\", metadata={'page': 8, 'source': 'docs/cs229_lectures/MachineLearning-Lecture01.pdf'})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compressed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "I extracted the following:\n",
      "\n",
      "\"So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \\\"Oh, professor, thank you so much for your...\"\n",
      "\n",
      "This is the part of the context that might be relevant to answering the question.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "I extracted the following:\n",
      "\n",
      "\"So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \\\"Oh, professor, thank you so much for your...\"\n",
      "\n",
      "This is the part of the context that might be relevant to answering the question.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "The relevant parts from the context are:\n",
      "\n",
      "- They talked about machine learning and how it helped with his work, and how he uses it daily. \n",
      "\n",
      "- They also mentioned a picture of his big house, which could be related to his success with the skills learned and possibly income. \n",
      "\n",
      "These are the parts that are most relevant to answering the question.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "The extracted relevant parts include:\n",
      "\n",
      "- They are discussing MATLAB and how it helps with machine learning and making money.\n",
      "- The conversation revolves around learning and using MATLAB as a tool to improve the student's knowledge and further career.\n",
      "\n",
      "- The conversation highlights the importance of MATLAB in machine learning and how it can help students create valuable skills and build their careers. \n",
      "\n",
      "These are the relevant parts of the context provided to answer the question.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining various techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever(search_type=\"mmr\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n",
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "compressed_docs = compression_retriever.get_relevant_documents(\n",
    "    query=question,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "I extracted the following:\n",
      "\n",
      "\"So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \\\"Oh, professor, thank you so much for your...\"\n",
      "\n",
      "This is the part of the context that might be relevant to answering the question.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "The relevant parts of the context are:\n",
      "\n",
      "- They are discussing a machine learning class and how the content was helpful. \n",
      "\n",
      "- They are talking about discussion sections and the purpose of them, which are to help students review topics they have not covered yet. \n",
      "\n",
      "- They are looking for a short MATLAB tutorial for students who are new to MATLAB.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "The relevant part of context for answering this question is:\n",
      "\n",
      "\"mathematical work, he feels like he's disc overing truth and beauty in the universe as revealed to him by the math he does.\" \n",
      "\n",
      "This part talks about the nature of mathematical exploration and the relationship between mathematical results and the perception of the truths and beauty of the universe.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "The relevant part of context for this question is about the example of using MATLAB to implement the algorithm and the discussion about supervised learning and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other types of retrieval\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as **TF-IDF** or **SVM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever, TFIDFRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = PyPDFLoader(\n",
    "    file_path=\"./docs/cs229_lectures/MachineLearning-Lecture01.pdf\"\n",
    ").load()\n",
    "\n",
    "all_page_text = [p.page_content for p in pages]\n",
    "\n",
    "joined_page_text = \" \".join(all_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "\n",
    "splits = text_splitter.split_text(text=joined_page_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_retriever = SVMRetriever.from_texts(texts=splits, embeddings=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_retriever = TFIDFRetriever.from_texts(texts=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "let me just check what questions you have righ t now. So if there are no questions, I'll just \n",
      "close with two reminders, which are after class today or as you start to talk with other \n",
      "people in this class, I just encourage you again to start to form project partners, to try to \n",
      "find project partners to do your project with. And also, this is a good time to start forming \n",
      "study groups, so either talk to your friends  or post in the newsgroup, but we just \n",
      "encourage you to try to star t to do both of those today, okay? Form study groups, and try \n",
      "to find two other project partners.  \n",
      "So thank you. I'm looking forward to teaching this class, and I'll see you in a couple of \n",
      "days.   [End of Audio]  \n",
      "Duration: 69 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyang/git-repos/ai-courses/deeplearning_ai/langchain_chat_with_data/.venv/lib/python3.10/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "question = \"What are major topics for this class?\"\n",
    "\n",
    "docs_svm = svm_retriever.get_relevant_documents(query=question)\n",
    "\n",
    "print(docs_svm[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saxena and Min Sun here did, wh ich is given an image like this, right? This is actually a \n",
      "picture taken of the Stanford campus. You can apply that sort of cl ustering algorithm and \n",
      "group the picture into regions. Let me actually blow that up so that you can see it more \n",
      "clearly. Okay. So in the middle, you see the lines sort of groupi ng the image together, \n",
      "grouping the image into [inaudible] regions.  \n",
      "And what Ashutosh and Min did was they then  applied the learning algorithm to say can \n",
      "we take this clustering and us e it to build a 3D model of the world? And so using the \n",
      "clustering, they then had a lear ning algorithm try to learn what the 3D structure of the \n",
      "world looks like so that they could come up with a 3D model that you can sort of fly \n",
      "through, okay? Although many people used to th ink it's not possible to take a single \n",
      "image and build a 3D model, but using a lear ning algorithm and that sort of clustering \n",
      "algorithm is the first step. They were able to.  \n",
      "I'll just show you one more example. I like this  because it's a picture of Stanford with our \n",
      "beautiful Stanford campus. So again, taking th e same sort of clustering algorithms, taking \n",
      "the same sort of unsupervised learning algor ithm, you can group the pixels into different \n",
      "regions. And using that as a pre-processing step, they eventually built this sort of 3D model of Stanford campus in a single picture.  You can sort of walk  into the ceiling, look\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about matlab?\"\n",
    "\n",
    "docs_tfidf = tfidf_retriever.get_relevant_documents(query=question)\n",
    "\n",
    "print(docs_tfidf[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
